########## Dune Queries ##########
[dune_queries.dex_volume]
query = "https://dune.com/queries/4388"
primary_key = ["project", "_col1"]
write_disposition = "merge"

##### dex volume incremental #####
[dune_queries.dex_volume_incremental]
query = "https://dune.com/queries/4778954"
primary_key = ["project", "date"]
write_disposition = "replace"
replication_key = "date" # make sure the name of the param in dune query matches name of the replication key
starting_replication_value = "2025-01-01"

##### example with query params #####
[dune_queries.y2k_price_data]
query = 4749625 # just the query id also works. Query URL: https://dune.com/queries/4749625
primary_key = ["timestamp", "blockchain", "contract_address"] # multi PK example
write_disposition = "merge"
query_params = '{"symbol": "Y2K"}'

##### example with custom SQL and incremental loading #####
[dune_queries.custom_sql]
query = """
SELECT 
    timestamp,
    blockchain,
    contract_address,
    symbol,
    price
FROM prices.day 
WHERE symbol = 'BRETT' 
AND blockchain = 'base'
AND contract_address = from_hex('532f27101965dd16442e59d40670faf5ebb142e4')
-- must use 'replication_key' and 'cursor_value' keywords for incremental loading
AND {replication_key} > TIMESTAMP '{cursor_value}' 
order by timestamp
"""
primary_key = "timestamp"
write_disposition = "merge"
replication_key = "timestamp"
starting_replication_value = "2024-11-01"



########## Snowflake Destination ##########
[destination.snowflake]
keep_staged_files = false # defaults to true otherwise (https://dlthub.com/docs/dlt-ecosystem/destinations/snowflake#data-loading)
